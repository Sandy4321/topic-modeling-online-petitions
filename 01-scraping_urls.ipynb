{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import division, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dateutil\n",
    "import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import re\n",
    "import html5lib\n",
    "\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selenium imports\n",
    "import selenium.selenium\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# timing function\n",
    "def timefunc(f):\n",
    "    def f_timer(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print f.__name__, 'took', end - start, 'seconds'\n",
    "        return result\n",
    "    return f_timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to scrape petition URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setting up chromedriver\n",
    "chromedriver = '/usr/bin/'\n",
    "os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# go straight to most-recent pages\n",
    "petitions_url = 'https://www.change.org/petitions#most-recent/' # up to 5084\n",
    "\n",
    "@timefunc\n",
    "def get_petition_urls(base, start, stop):\n",
    "    d = {}\n",
    "    for i in range(start, stop+1):\n",
    "        driver.get(base + str(i))\n",
    "        petitions = driver.find_elements_by_xpath('//div[@class = \"petition-list\"]//ol//li[@class = \"petition\"]')\n",
    "        for p in petitions:\n",
    "            d[p.get_attribute('data-id')] = p.get_attribute('data-url')\n",
    "    return d\n",
    "\n",
    "@timefunc\n",
    "def chunk_petition_urls(dic, base, first, last, chunk):\n",
    "    for c in range(first, last+1, chunk):\n",
    "        d = get_petition_urls(base, c, c+chunk)\n",
    "        dic.update(d)\n",
    "        filename = 'master' + str(c+chunk) + '.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pk.dump(dic,f,-1)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating master dictionary of petition URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 83.6022620201 seconds\n",
      "get_petition_urls took 116.554121017 seconds\n",
      "get_petition_urls took 118.026024103 seconds\n",
      "get_petition_urls took 112.562197924 seconds\n",
      "get_petition_urls took 113.29539299 seconds\n",
      "get_petition_urls took 118.685126066 seconds\n",
      "get_petition_urls took 113.570473909 seconds\n",
      "get_petition_urls took 119.098234177 seconds\n",
      "get_petition_urls took 118.850047827 seconds\n",
      "get_petition_urls took 117.617727995 seconds\n",
      "chunk_petition_urls took 1132.55802894 seconds\n"
     ]
    }
   ],
   "source": [
    "urls1000 = chunk_petition_urls(master, petitions_url, 1, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 471.196193933 seconds\n",
      "get_petition_urls took 516.103647947 seconds\n",
      "get_petition_urls took 526.678014994 seconds\n",
      "get_petition_urls took 518.661587 seconds\n",
      "get_petition_urls took 419.599153996 seconds\n",
      "get_petition_urls took 515.13568306 seconds\n",
      "get_petition_urls took 562.423695087 seconds\n",
      "get_petition_urls took 569.604753017 seconds\n",
      "get_petition_urls took 553.038632154 seconds\n",
      "get_petition_urls took 539.273699045 seconds\n",
      "chunk_petition_urls took 5193.3154161 seconds\n"
     ]
    }
   ],
   "source": [
    "urls2000 = chunk_petition_urls(master, petitions_url, 1001, 2000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 507.515866995 seconds\n",
      "get_petition_urls took 561.443950891 seconds\n",
      "get_petition_urls took 560.142756939 seconds\n",
      "get_petition_urls took 585.547399044 seconds\n",
      "get_petition_urls took 550.640335083 seconds\n",
      "get_petition_urls took 516.350791931 seconds\n",
      "get_petition_urls took 578.102795124 seconds\n",
      "get_petition_urls took 556.191126823 seconds\n",
      "get_petition_urls took 534.958039999 seconds\n",
      "get_petition_urls took 479.614413023 seconds\n",
      "chunk_petition_urls took 5433.15993118 seconds\n"
     ]
    }
   ],
   "source": [
    "urls3000 = chunk_petition_urls(master, petitions_url, 2001, 3000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 467.728751898 seconds\n",
      "get_petition_urls took 528.480911016 seconds\n",
      "get_petition_urls took 568.805104971 seconds\n",
      "get_petition_urls took 557.964962006 seconds\n",
      "get_petition_urls took 541.561532974 seconds\n",
      "get_petition_urls took 575.63617897 seconds\n",
      "get_petition_urls took 565.878679991 seconds\n",
      "get_petition_urls took 567.511631966 seconds\n",
      "get_petition_urls took 535.09702611 seconds\n",
      "get_petition_urls took 499.659738064 seconds\n",
      "chunk_petition_urls took 5411.80708313 seconds\n"
     ]
    }
   ],
   "source": [
    "urls4000 = chunk_petition_urls(master, petitions_url, 3001, 4000, 100) # got up to pg. 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 428.591609001 seconds\n",
      "get_petition_urls took 520.487569809 seconds\n",
      "get_petition_urls took 506.646430016 seconds\n",
      "get_petition_urls took 521.768352032 seconds\n",
      "get_petition_urls took 519.604418993 seconds\n",
      "get_petition_urls took 520.35282588 seconds\n",
      "get_petition_urls took 519.105734825 seconds\n",
      "get_petition_urls took 522.381052017 seconds\n",
      "get_petition_urls took 522.740482807 seconds\n",
      "get_petition_urls took 425.205639839 seconds\n",
      "chunk_petition_urls took 5011.190166 seconds\n"
     ]
    }
   ],
   "source": [
    "urls5000 = chunk_petition_urls(master, petitions_url, 4001, 5000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 6.02406811714 seconds\n",
      "get_petition_urls took 1.42188501358 seconds\n",
      "get_petition_urls took 1.35270404816 seconds\n",
      "get_petition_urls took 1.62045907974 seconds\n",
      "get_petition_urls took 1.34431195259 seconds\n",
      "get_petition_urls took 1.47339487076 seconds\n",
      "get_petition_urls took 1.54480791092 seconds\n",
      "get_petition_urls took 1.03821110725 seconds\n",
      "chunk_petition_urls took 19.9333100319 seconds\n"
     ]
    }
   ],
   "source": [
    "urls5080 = chunk_petition_urls(master, petitions_url, 5001, 5080, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_petition_urls took 0.748665809631 seconds\n",
      "get_petition_urls took 0.594233989716 seconds\n",
      "chunk_petition_urls took 2.56482005119 seconds\n"
     ]
    }
   ],
   "source": [
    "urls5084 = chunk_petition_urls(master, petitions_url, 5081, 5084, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48966"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('master5085.pkl', 'wb') as f:\n",
    "    master = pk.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code to pull petition information with Selenium\n",
    "Code not used; wrote scrapy spider to crawl for petition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add number of supporters in initial url comb - refresh\n",
    "petitions_url = 'https://www.change.org/petitions#most-recent/' # up to 5084\n",
    "\n",
    "@timefunc\n",
    "def get_petition_urls(base, start, stop):\n",
    "    d = {}\n",
    "    for i in range(start,stop+1):\n",
    "        driver.get(base + str(i))\n",
    "        petitions = driver.find_elements_by_xpath('//div[@class = \"petition-list\"]//ol//li[@class = \"petition\"]')\n",
    "        for p in petitions:\n",
    "            data_id = p.get_attribute('data-id')\n",
    "            url = p.get_attribute('data-url')\n",
    "            try:\n",
    "                for title_holder in p.find_elements_by_xpath('.//h3'):\n",
    "                    title = title_holder.text\n",
    "            except:\n",
    "                title = ''\n",
    "            try:\n",
    "                group_id = p.get_attribute('data-petition_group_id')\n",
    "            except:\n",
    "                group_id = ''\n",
    "            try:\n",
    "                for supporter_holder in p.find_elements_by_xpath('.//div[@class=\"weak\"]'):\n",
    "                    supporter = supporter_holder.text.split()[0].replace(',','')\n",
    "            except: \n",
    "                supporter = ''\n",
    "            d[data_id] = {'id': data_id,\n",
    "                          'title': title,\n",
    "                          'url': url,\n",
    "                         'group_id': group_id,\n",
    "                         'supporters': supporter}\n",
    "    return d\n",
    "\n",
    "@timefunc\n",
    "def chunk_petition_urls(dic, base, first, last, chunk):\n",
    "    for c in range(first, last+1, chunk):\n",
    "        d = get_petition_urls(base, c, c+chunk)\n",
    "        dic.update(d)\n",
    "        filename = 'master_plus' + str(c+chunk) + '.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pk.dump(dic,f,-1)\n",
    "    return dic\n",
    "\n",
    "# WITH TRIES\n",
    "@timefunc\n",
    "def get_victory_urls(base, start, stop):\n",
    "    d = {}\n",
    "    for i in range(start,stop+1):\n",
    "        driver.get(base + str(i))\n",
    "        victories = driver.find_elements_by_xpath('//div[@class = \"petition-list\"]//ol//li[@class = \"petition\"]')\n",
    "        for i, v in enumerate(victories):\n",
    "            data_id = i\n",
    "            url = v.get_attribute('data-url')\n",
    "            try:\n",
    "                for title_holder in v.find_elements_by_xpath('.//h3'):\n",
    "                    victory_title = title_holder.text\n",
    "            except:\n",
    "                victory_title = ''\n",
    "            try:\n",
    "                group_id = v.get_attribute('data-petition_group_id')\n",
    "            except:\n",
    "                group_id = ''\n",
    "            try:\n",
    "                for supporter_holder in v.find_elements_by_xpath('.//div[@class=\"weak\"]'):\n",
    "                    supporter = supporter_holder.text.split()[0].replace(',','')\n",
    "            except: \n",
    "                supporter = ''\n",
    "            try:\n",
    "                for date_holder in v.find_elements_by_xpath('.//li'):\n",
    "                    victory_date = date_holder.text\n",
    "            except:\n",
    "                victory_date = ''\n",
    "            try:\n",
    "                for blurb_holder in v.find_elements_by_xpath('.//p[@class=\"victory-update\"]'):\n",
    "                    victory_blurb = blurb_holder.text\n",
    "            except:\n",
    "                victory_blurb = ''\n",
    "            d[data_id] = {'victory_title': victory_title,\n",
    "                          'victory_blurb': victory_blurb,\n",
    "                          'victory_date': victory_date,\n",
    "                          'url': url,\n",
    "                          'supporters': supporter}\n",
    "    return d\n",
    "\n",
    "@timefunc\n",
    "def chunk_victory_urls(dic, base, first, last, chunk):\n",
    "    for c in range(first, last+1, chunk):\n",
    "        d = get_victory_urls(base, c, c+chunk)\n",
    "        dic.update(d)\n",
    "        filename = 'victories' + str(c+chunk) + '.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pk.dump(dic,f,-1)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting URLs of victorious petitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up chromedriver\n",
    "chromedriver = '/usr/bin/'\n",
    "os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "victories_url = 'https://www.change.org/victories#most-recent/' # up to 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timefunc\n",
    "def get_victory_urls(base, start, stop):\n",
    "    d = {}\n",
    "    for i in range(start, stop+1):\n",
    "        driver.get(base + str(i))\n",
    "        victories = driver.find_elements_by_xpath('//div[@class = \"petition-list\"]//ol//li[@class = \"petition\"]')\n",
    "        for i, v in enumerate(victories):\n",
    "            d[i] = v.get_attribute('data-url')\n",
    "    return d\n",
    "\n",
    "@timefunc\n",
    "def chunk_victory_urls(dic, base, first, last, chunk):\n",
    "    for c in range(first, last+1, chunk):\n",
    "        d = get_victory_urls(base, c, c+chunk)\n",
    "        dic.update(d)\n",
    "        filename = 'victories' + str(c+chunk) + '.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pk.dump(dic,f,-1)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "victories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_victory_urls took 5650.60482502 seconds\n"
     ]
    }
   ],
   "source": [
    "victories = get_victory_urls(victories_url, 1, 368)\n",
    "filename = 'victories_final.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pk.dump(victories,f,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3630"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(victories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code to pull victorous petition information with Selenium\n",
    "Code not used; wrote scrapy spider to crawl for petition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = '/usr/bin/'\n",
    "os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_url = 'https://www.change.org/victories#most-recent/2'\n",
    "\n",
    "d = {}\n",
    "\n",
    "driver.get(test_url)\n",
    "\n",
    "sleep(2)\n",
    "\n",
    "victories = driver.find_elements_by_xpath('//div[@class = \"petition-list\"]//ol//li[@class = \"petition\"]')\n",
    "for i, v in enumerate(victories):\n",
    "    data_id = i\n",
    "    url = v.get_attribute('data-url')\n",
    "    try:\n",
    "        for title_holder in v.find_elements_by_xpath('.//h3'):\n",
    "            victory_title = title_holder.text\n",
    "    except:\n",
    "        victory_title = ''\n",
    "    try:\n",
    "        group_id = v.get_attribute('data-petition_group_id')\n",
    "    except:\n",
    "        group_id = ''\n",
    "    try:\n",
    "        for supporter_holder in v.find_elements_by_xpath('.//div[@class=\"weak\"]'):\n",
    "            supporter = supporter_holder.text.split()[0].replace(',','')\n",
    "    except: \n",
    "        supporter = ''\n",
    "    try:\n",
    "        for date_holder in v.find_elements_by_xpath('.//li'):\n",
    "            victory_date = date_holder.text\n",
    "    except:\n",
    "        victory_date = ''\n",
    "    try:\n",
    "        for blurb_holder in v.find_elements_by_xpath('.//p[@class=\"victory-update\"]'):\n",
    "            victory_blurb = blurb_holder.text\n",
    "    except:\n",
    "        victory_blurb = ''\n",
    "    d[data_id] = {'victory_title': victory_title,\n",
    "                  'victory_blurb': victory_blurb,\n",
    "                  'victory_date': victory_date,\n",
    "                  'url': url,\n",
    "                  'supporters': supporter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {u'supporters': u'91045',\n",
       "  u'url': u'https://www.change.org/p/aramark-stop-abusing-chickens',\n",
       "  u'victory_blurb': u'',\n",
       "  u'victory_date': u'November 2016',\n",
       "  u'victory_title': u'Aramark: Stop Abusing Chickens'},\n",
       " 1: {u'supporters': u'140767',\n",
       "  u'url': u'https://www.change.org/p/urge-congress-to-support-rape-survivor-rights',\n",
       "  u'victory_blurb': u\"On October 7, 2016, President Obama signed the first ever Sexual Assault Survivors' Bill of Rights into law. Championed by Amanda Nguyen and her organization Rise, this important legislation will help provide civil rights and protections to more than 25 million sexual assault survivors.\",\n",
       "  u'victory_date': u'October 2016',\n",
       "  u'victory_title': u\"Congress passes Sexual Assautl Survivors' Bill of Rights\"},\n",
       " 2: {u'supporters': u'154580',\n",
       "  u'url': u'https://www.change.org/p/my-dad-will-die-in-prison-for-a-nonviolent-drug-offense',\n",
       "  u'victory_blurb': u\"On October 6, 2016, President Obama commuted the sentences of 102 federal inmates including Ricky Minor's. Over 150,000 people signed this petition started by Ricky's daughter asking the president to commute her father's sentence. Ricky has spent over 15 years in prison for a first time nonviolent drug offense.\",\n",
       "  u'victory_date': u'October 2016',\n",
       "  u'victory_title': u\"President Obama commutes Ricky Minor's life sentence\"},\n",
       " 3: {u'supporters': u'6803',\n",
       "  u'url': u'https://www.change.org/p/massachussets-legislators-support-rape-survivor-rights',\n",
       "  u'victory_blurb': u\"On October 6, the Sexual Assault Survivors' Bill of Rights passed in Massachusetts. This was Rise's first legislative endeavor as an organization, and it laid the groundwork for all of the work that we have done since and will continue to do.\",\n",
       "  u'victory_date': u'October 2016',\n",
       "  u'victory_title': u\"Massachussets Passes Sexual Assault Survivors' Bill of Rights\"},\n",
       " 4: {u'supporters': u'48942',\n",
       "  u'url': u'https://www.change.org/p/proteggiamo-il-made-in-italy-la-pizza-come-patrimonio-unesco-2',\n",
       "  u'victory_blurb': u'',\n",
       "  u'victory_date': u'September 2016',\n",
       "  u'victory_title': u'Proteggiamo il made in Italy: la pizza come patrimonio Unesco'},\n",
       " 5: {u'supporters': u'423305',\n",
       "  u'url': u'https://www.change.org/p/my-brother-was-sentenced-to-life-without-parole-for-a-nonviolent-drug-offense',\n",
       "  u'victory_blurb': u\"On August 30, 2016, President Obama granted clemency to Timothy Tyler who was serving a life sentence for selling LSD. Over 423,000 people signed Timothy\\u2019s petition on Change.org, started by his sister Carrie, who advocated for Tim's freedom tirelessly. Tim was just 25 years old when he was sentenced and spent half of his life in prison. Without clemency for President Obama, he would have died behind bars.\",\n",
       "  u'victory_date': u'August 2016',\n",
       "  u'victory_title': u\"President Obama commutes Timothy Tyler's life sentence\"},\n",
       " 6: {u'supporters': u'60985',\n",
       "  u'url': u'https://www.change.org/p/president-obama-grant-clemency-to-danielle-metz-serving-life-without-parole',\n",
       "  u'victory_blurb': u'On August 30, 2016, President Obama granted clemency to Danielle Metz who was serving a life sentence for a first time nonviolent drug offense. Over 60,000 people signed Danielle\\u2019s petition on Change.org, started by her daughter Gleneisha. Without clemency for President Obama, Danielle would have died behind bars.',\n",
       "  u'victory_date': u'August 2016',\n",
       "  u'victory_title': u\"President Obama commutes Danielle Metz's life sentence\"},\n",
       " 7: {u'supporters': u'107160',\n",
       "  u'url': u'https://www.change.org/p/casino-reinvestment-development-authority-stop-your-lawsuit-to-bulldoze-my-longtime-family-home',\n",
       "  u'victory_blurb': u'In a ruling that may bring an end to the years-long battle to save Charlie Birnbaum\\u2019s longtime family home from condemnation, Judge Julio Mendez today ruled that the Casino Reinvestment Development Authority\\u2019s attempt to take Birnbaum\\u2019s property was \\u201ca manifest abuse of the eminent domain power\\u201d and dismissed the state\\u2019s condemnation action once and for all. Charlie Birnbaum was elated by the ruling: \\u201cWe have the rest of our lives to let it sink in. It\\u2019s like watching a miracle unfold. I\\u2019ve realized that this is not just my victory. I can share this with anyone who is facing unjustified government action. If Charlie Birnbaum can win against the state of New Jersey, then there\\u2019s hope for anybody. It\\u2019s a legacy I can pass down to my children.\\u201d',\n",
       "  u'victory_date': u'August 2016',\n",
       "  u'victory_title': u'Judge Sides With Piano Man Against Government Land Grab'},\n",
       " 8: {u'supporters': u'85106',\n",
       "  u'url': u'https://www.change.org/p/barack-obama-grant-clemency-to-dicky-joe-jackson',\n",
       "  u'victory_blurb': u\"On August 3, 2016, President Obama commuted the sentences of 214 federal inmates including Dicky Joe Jackson's. This was the largest single-day grant of commutations in the nation's history. Jackson served over 20 years of a life sentence after being convicted of conspiracy to possess and distribute methamphetamine which he did because he couldn't afford the $250,000 life saving bone-marrow transplant for his two-year-old son.\",\n",
       "  u'victory_date': u'August 2016',\n",
       "  u'victory_title': u'President Obama Grants Clemency to Dicky Joe Jackson'},\n",
       " 9: {u'supporters': u'259',\n",
       "  u'url': u'https://www.change.org/p/barack-obama-commute-the-sentence-of-charceil-kellam',\n",
       "  u'victory_blurb': u\"On August 3, 2016, President Obama commuted the sentences of 214 federal inmates including Charceil Kellam's -- the largest single-day grant of commutations in the nation's history.\",\n",
       "  u'victory_date': u'August 2016',\n",
       "  u'victory_title': u'President Obama grants clemency to Charceil Kellam'}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
